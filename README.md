
## Information
Left off: Naive Bayes classifier


## Table of Contents

###ยง 1 - [Classification and Regression using Supervised Learning](#1-classification-and-regression-using-supervised-learning)


## TO LEARN

* Reason and means for the process of "Removing the mean"
* Scalar Min Max
* L1 Normalization
* L2 Normalization


## Glossary

####Logistic Regression**

Used to explain the relationship between input variables and output variables. The input remains independent while the
output remains dependent on a fixed set of values. These values relate to the classes derived from the classification 
problem. 

We want to identify the relationship between the input and output by estimating the probabilities with a
logistic function - a **sigmoid curve**.


####Normalization

**Least Absolute Normalization (L1 Normalization)**

Makes sure that the sum of absolute values equals 1 in each row. This is better for datasets where you DON'T care about
the outliers.

**Least Squared Normalization (L2 Normalization)**

Makes sure that the sum of squared values equals 1 in each row. This is better for datasets where you DO care about
the outliers.


####Sigmoid Curve